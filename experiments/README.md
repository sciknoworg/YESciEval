
## ğŸ—ƒï¸ ScienceQ&A Dataset

The `dataset/` directory contains data for the **BioASQ** and **ORKG-Synthesis** datasets, organized into `train` and `test` sets. Each set consists of three categories: `adversarial-extreme`, `adversarial-subtle`, and `benign`. The `dataset/` directory structured as follows:
```angular2html
dataset/
â”œâ”€â”€ BioASQ
â”‚Â Â  â”œâ”€â”€ test/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ adversarial_extreme/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ adversarial_subtle/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ original_synthesis/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ BioASQ_dataset_adversarial_extreme_clean.xlsx
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ BioASQ_dataset_adversarial_subtle_clean.xlsx
â”‚Â Â  â”‚Â Â  â””â”€â”€ BioASQ_dataset_synthesis.xlsx
â”‚Â Â  â”œâ”€â”€ train/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ adversarial_extreme/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ adversarial_subtle/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ original_synthesis/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ BioASQ_dataset_adversarial_extreme_clean.xlsx
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ BioASQ_dataset_adversarial_subtle_clean.xlsx
â”‚Â Â  â”‚Â Â  â””â”€â”€ BioASQ_dataset_synthesis.xlsx
â”‚Â Â  â””â”€â”€ train_test_split_ids.json
â””â”€â”€ ORKG-Synthesis
    â”œâ”€â”€ test
    â”‚Â Â  â”œâ”€â”€ adversarial_extreme/
    â”‚Â Â  â”œâ”€â”€ adversarial_subtle/
    â”‚Â Â  â”œâ”€â”€ original_synthesis/
    â”‚Â Â  â”œâ”€â”€ llm4syn_dataset_adversarial_extreme_clean.xlsx
    â”‚Â Â  â”œâ”€â”€ llm4syn_dataset_adversarial_subtle_clean.xlsx
    â”‚Â Â  â”œâ”€â”€ llm4syn_dataset_synthesis.xlsx
    â”‚Â Â  â””â”€â”€ original_synthesis
    â”œâ”€â”€ train
    â”‚Â Â  â”œâ”€â”€ adversarial_extreme/
    â”‚Â Â  â”œâ”€â”€ adversarial_subtle/
    â”‚Â Â  â”œâ”€â”€ original_synthesis/
    â”‚Â Â  â”œâ”€â”€ llm4syn_dataset_adversarial_extreme_clean.xlsx
    â”‚Â Â  â”œâ”€â”€ llm4syn_dataset_adversarial_subtle_clean.xlsx
    â”‚Â Â  â””â”€â”€ llm4syn_dataset_synthesis.xlsx
    â””â”€â”€ train_test_split_ids.json
```

### ğŸ“• How to run the experimentation?  

**HINT**: Using the YESciEval is an optimal way of doing this.

The first step is to generate adversarial sets using the `generator/` directory. However, these sets are already available in the repository. To fine-tune your judge model, follow these steps:  

1. ğŸ¤– **Supervised Fine-Tuning (SFT):**  Run the supervised fine-tuning model with the following command:  
```cmd
   python supervised_finetuning.py
```
2. ğŸ¤– **Reinforcement Learning (RL)** Fine-Tuning: After completing SFT, continue fine-tuning using reinforcement learning:

```cmd
python reinforcement_learning.py
```
3.   ğŸ“Š **Inference and Evaluation**: To evaluate and use your judge model, run any of the `*_inference.py` scripts:
```cmd
python your_inference_script.py
```
